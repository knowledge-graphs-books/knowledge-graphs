{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, CSV\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Define the SPARQL endpoint and query\n",
    "endpoint_url = \"https://dbpedia.org/sparql\"\n",
    "def make_query(batch_size = 1000, offset = 0):\n",
    "  return\"\"\"\n",
    "PREFIX rdf:  <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX dbo:  <http://dbpedia.org/ontology/>\n",
    "PREFIX dbp:  <http://dbpedia.org/property/>\n",
    "\n",
    "SELECT DISTINCT ?filmTitle ?filmGenre ?bookTitle ?bookGenre ?author ?authorName ?birthDate\n",
    "WHERE {\n",
    "  # Ensure the resource is typed as a Film\n",
    "  ?film rdf:type dbo:Film .\n",
    "  \n",
    "  # Check both dbo:basedOn and dbp:basedOn for the relation to the book\n",
    "  {\n",
    "    ?film dbo:basedOn ?book .\n",
    "  }\n",
    "  UNION\n",
    "  {\n",
    "    ?film dbp:basedOn ?book .\n",
    "  }\n",
    "  \n",
    "  # Retrieve film labels in English\n",
    "  ?film rdfs:label ?filmTitle .\n",
    "  FILTER (lang(?filmTitle) = \"en\")\n",
    "\n",
    "  # --------------------------------------------\n",
    "  # 1) Film Genre (optional, because not all films have dbo:genre)\n",
    "  # --------------------------------------------\n",
    "  OPTIONAL {\n",
    "    ?film dbo:genre ?filmGenreResource .\n",
    "    ?filmGenreResource rdfs:label ?filmGenre .\n",
    "    FILTER (lang(?filmGenre) = \"en\")\n",
    "  }\n",
    "\n",
    "  # Retrieve book label in English\n",
    "  ?book rdfs:label ?bookTitle .\n",
    "  FILTER (lang(?bookTitle) = \"en\")\n",
    "\n",
    "  # --------------------------------------------\n",
    "  # 2) Book Genre (optional, because not all books have dbo:genre)\n",
    "  # --------------------------------------------\n",
    "  OPTIONAL {\n",
    "    ?book dbo:genre ?bookGenreResource .\n",
    "    ?bookGenreResource rdfs:label ?bookGenre .\n",
    "    FILTER (lang(?bookGenre) = \"en\")\n",
    "  }\n",
    "\n",
    "  # --------------------------------------------\n",
    "  # 3) Book Author and Birth Date (both optional)\n",
    "  # --------------------------------------------\n",
    "  OPTIONAL {\n",
    "    ?book dbo:author ?author .\n",
    "    ?author rdfs:label ?authorName .\n",
    "    FILTER (lang(?authorName) = \"en\")\n",
    "\n",
    "    OPTIONAL {\n",
    "      ?author dbo:birthDate ?birthDate .\n",
    "    }\n",
    "  }\n",
    "}\n",
    "ORDER BY ?filmTitle\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows acquired in this batch: 1166 | Total rows: 1166\n",
      "Total rows acquired: 1166\n",
      "                         filmTitle filmGenre                      bookTitle  \\\n",
      "0                       18.05.2009       NaN           Sri Lankan Civil War   \n",
      "1                     200 Halla Ho       NaN                     Akku Yadav   \n",
      "2                          27 Guns       NaN               Ugandan Bush War   \n",
      "3      50 Million Frenchmen (film)       NaN                 Herbert Fields   \n",
      "4      50 Million Frenchmen (film)       NaN                    Cole Porter   \n",
      "...                            ...       ...                            ...   \n",
      "1161                   Yugadrashta       NaN          Pitambar Deva Goswami   \n",
      "1162  Zack Snyder's Justice League       NaN  Lists of DC Comics characters   \n",
      "1163            Zameer (2005 film)       NaN              Mazhayethum Munpe   \n",
      "1164               Zehreela Insaan       NaN                   Naagarahaavu   \n",
      "1165     Zorro (1975 Italian film)       NaN                          Zorro   \n",
      "\n",
      "     bookGenre author authorName birthDate  \n",
      "0          NaN    NaN        NaN       NaN  \n",
      "1          NaN    NaN        NaN       NaN  \n",
      "2          NaN    NaN        NaN       NaN  \n",
      "3          NaN    NaN        NaN       NaN  \n",
      "4          NaN    NaN        NaN       NaN  \n",
      "...        ...    ...        ...       ...  \n",
      "1161       NaN    NaN        NaN       NaN  \n",
      "1162       NaN    NaN        NaN       NaN  \n",
      "1163       NaN    NaN        NaN       NaN  \n",
      "1164       NaN    NaN        NaN       NaN  \n",
      "1165       NaN    NaN        NaN       NaN  \n",
      "\n",
      "[1166 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, CSV\n",
    "from io import StringIO\n",
    "\n",
    "# SPARQL Endpoint and Query\n",
    "endpoint_url = \"https://dbpedia.org/sparql\"\n",
    "batch_size = 500\n",
    "offset = 0\n",
    "total_rows = 0  # Counter for the total rows\n",
    "\n",
    "sparql = SPARQLWrapper(endpoint_url)\n",
    "sparql.setReturnFormat(CSV)\n",
    "sparql.setTimeout(300)\n",
    "# Initialize an empty DataFrame to store all results\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Estimated total pages\n",
    "max_pages = 60\n",
    "\n",
    "# Progress bar setup\n",
    "# Update the query with the current OFFSET\n",
    "paginated_query = make_query(batch_size, offset)\n",
    "sparql.setQuery(paginated_query)\n",
    "\n",
    "# Execute the query and fetch results\n",
    "results = sparql.query().convert()\n",
    "csv_str = results.decode(\"utf-8\")\n",
    "data = pd.read_csv(StringIO(csv_str))\n",
    "\n",
    "# If no data is returned, stop the loop\n",
    "# if data.empty:\n",
    "#     print(f\"No more data after offset {offset}.\")\n",
    "#     break\n",
    "\n",
    "# Append the current batch to the all_data DataFrame\n",
    "all_data = pd.concat([all_data, data], ignore_index=True)\n",
    "\n",
    "# Update total rows count\n",
    "total_rows += len(data)\n",
    "print(f\"Rows acquired in this batch: {len(data)} | Total rows: {total_rows}\")\n",
    "\n",
    "# Increment the offset for the next batch\n",
    "offset += batch_size\n",
    "\n",
    "# Optionally, save to CSV\n",
    "all_data.to_csv(\"tmp_adaptations_data.csv\", index=False)\n",
    "        \n",
    "\n",
    "# Print the final DataFrame and total rows\n",
    "print(f\"Total rows acquired: {total_rows}\")\n",
    "print(all_data)\n",
    "\n",
    "all_data.to_csv(\"adaptations_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rdflib import Graph, Namespace, Literal, RDF, URIRef\n",
    "from rdflib.namespace import XSD, RDFS\n",
    "import datetime\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# --------------------------\n",
    "# Helper functions\n",
    "# --------------------------\n",
    "\n",
    "def split_and_clean(s):\n",
    "    \"\"\"\n",
    "    Utility function to split comma or newline separated strings and clean them up.\n",
    "    \"\"\"\n",
    "    if pd.isna(s):\n",
    "        return []\n",
    "    items = []\n",
    "    # Split by commas, then split by newlines if necessary\n",
    "    for item in s.split(\",\"):\n",
    "        items.extend(item.split(\"\\n\"))\n",
    "    # Remove punctuation, strip spaces, and title-case\n",
    "    clean_items = [re.sub(r'[^a-zA-Z0-9 ]', '', x.strip()).strip().title() for x in items if x.strip()]\n",
    "    return clean_items\n",
    "\n",
    "def safe_uri(base, raw_name):\n",
    "    \"\"\"\n",
    "    Convert a raw string to a safe URI by removing or encoding special characters and lowercasing.\n",
    "    \"\"\"\n",
    "    # Replace spaces with underscores, remove non-alphanumeric underscores, then lowercase\n",
    "    clean_name = re.sub(r'[^a-zA-Z0-9_]+', '', raw_name.replace(\" \", \"_\")).lower()\n",
    "    return URIRef(base + clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Invalid date format '-065-12-08' for author 'Horace'. Skipping.\n",
      "1939-04-12\n",
      "1880-11-25\n",
      "1968-09-23\n",
      "1914-08-09\n",
      "1908-01-19\n",
      "1920-03-08\n",
      "1818-07-30\n",
      "1547-09-29\n",
      "1774-08-12\n",
      "1896-06-18\n",
      "1888-09-16\n",
      "1975-07-21\n",
      "1914-05-19\n",
      "1923-09-20\n",
      "1935-12-08\n",
      "1805-04-02\n",
      "1566-02-15\n",
      "1628-01-12\n",
      "1835-11-30\n",
      "1812-02-07\n",
      "1896-07-19\n",
      "1933-07-02\n",
      "1918-04-16\n",
      "1833-08-28\n",
      "1957-01-24\n",
      "1876-08-12\n",
      "1873-08-18\n",
      "1961-06-23\n",
      "1973-12-24\n",
      "1921-02-21\n",
      "1936-01-28\n",
      "Ontology successfully saved as authors_ontology_20250124_143007.owl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read CSV\n",
    "df = pd.read_csv(\"authors_fixed.csv\")\n",
    "\n",
    "# Pre-process data\n",
    "df[\"author_id\"] = df['authorLabel'].astype(str)  # Create a unique ID for each author\n",
    "df['genres_list'] = df['combinedGenres'].apply(split_and_clean)\n",
    "df['books_list']  = df['topBooks'].apply(split_and_clean)\n",
    "df = df.drop_duplicates(subset=['author_id'])\n",
    "\n",
    "# Initialize an RDFLib graph\n",
    "graph = Graph()\n",
    "\n",
    "# Define the base namespace for our ontology\n",
    "BASE = \"http://www.semanticweb.org/admin/ontologies/2024/9/authors-ontology#\"\n",
    "ONS = Namespace(BASE)\n",
    "graph.bind(\"ons\", ONS)\n",
    "\n",
    "# Define our classes\n",
    "AUTHOR_CLASS = ONS.Author\n",
    "GENRE_CLASS  = ONS.Genre\n",
    "BOOK_CLASS   = ONS.Book\n",
    "NATLANG_CLASS = ONS.NationalityOrLanguage\n",
    "FILM_CLASS    = ONS.Film\n",
    "\n",
    "# Add RDF:Class statements to the graph for clarity\n",
    "graph.add((AUTHOR_CLASS, RDF.type, RDFS.Class))\n",
    "graph.add((GENRE_CLASS,  RDF.type, RDFS.Class))\n",
    "graph.add((BOOK_CLASS,   RDF.type, RDFS.Class))\n",
    "graph.add((NATLANG_CLASS, RDF.type, RDFS.Class))\n",
    "graph.add((FILM_CLASS,    RDF.type, RDFS.Class))\n",
    "\n",
    "# Define properties (object/data properties)\n",
    "# For example: hasGenre, wroteBook, hasNationality, name, birthDate, etc.\n",
    "HAS_GENRE       = ONS.hasGenre\n",
    "WROTE_BOOK      = ONS.wroteBook\n",
    "HAS_NATLANG     = ONS.hasNationalityOrLanguage\n",
    "NAME            = ONS.name\n",
    "BIRTH_DATE      = ONS.birthDate\n",
    "ADAPTED_FROM_BOOK   = ONS.adaptedFromBook\n",
    "\n",
    "# A helper dictionary to store references to existing URIs (for re-use)\n",
    "# This helps avoid duplicating the same genre/book/nationality resource\n",
    "known_genres = {}\n",
    "known_books  = {}\n",
    "known_natlang = {}\n",
    "known_authors  = {} \n",
    "known_films    = {}\n",
    "\n",
    "def add_genre(genre_name):\n",
    "    \"\"\"\n",
    "    Create or retrieve a genre resource in the graph.\n",
    "    \"\"\"\n",
    "    if genre_name not in known_genres:\n",
    "        genre_uri = safe_uri(BASE, f\"genre_{genre_name}\")\n",
    "        # Add triple: (genre_uri, RDF.type, GENRE_CLASS)\n",
    "        graph.add((genre_uri, RDF.type, GENRE_CLASS))\n",
    "        # Add triple: (genre_uri, RDFS.label, Literal(genre_name))\n",
    "        graph.add((genre_uri, RDFS.label, Literal(genre_name)))\n",
    "        # You could also store a 'name' property\n",
    "        graph.add((genre_uri, NAME, Literal(genre_name)))\n",
    "        known_genres[genre_name] = genre_uri\n",
    "    return known_genres[genre_name]\n",
    "\n",
    "def add_book(book_title):\n",
    "    \"\"\"\n",
    "    Create or retrieve a book resource in the graph.\n",
    "    \"\"\"\n",
    "    if book_title not in known_books:\n",
    "        book_uri = safe_uri(BASE, f\"book_{book_title}\")\n",
    "        graph.add((book_uri, RDF.type, BOOK_CLASS))\n",
    "        graph.add((book_uri, RDFS.label, Literal(book_title)))\n",
    "        graph.add((book_uri, NAME, Literal(book_title)))\n",
    "        known_books[book_title] = book_uri\n",
    "    return known_books[book_title]\n",
    "\n",
    "def add_natlang(natlang):\n",
    "    \"\"\"\n",
    "    Create or retrieve a NationalityOrLanguage resource in the graph.\n",
    "    \"\"\"\n",
    "    if natlang not in known_natlang:\n",
    "        natlang_uri = safe_uri(BASE, f\"natlang_{natlang}\")\n",
    "        graph.add((natlang_uri, RDF.type, NATLANG_CLASS))\n",
    "        graph.add((natlang_uri, RDFS.label, Literal(natlang)))\n",
    "        graph.add((natlang_uri, NAME, Literal(natlang)))\n",
    "        known_natlang[natlang] = natlang_uri\n",
    "    return known_natlang[natlang]\n",
    "\n",
    "def add_author(row):\n",
    "    \"\"\"\n",
    "    Create or retrieve an Author resource, and add properties and links.\n",
    "    \"\"\"\n",
    "    author_name = row[\"authorLabel\"]\n",
    "    author_uri = safe_uri(BASE, f\"author_{author_name}\")\n",
    "    \n",
    "    # Add type triple\n",
    "    graph.add((author_uri, RDF.type, AUTHOR_CLASS))\n",
    "    # Add name triple\n",
    "    graph.add((author_uri, NAME, Literal(author_name)))\n",
    "\n",
    "    # If birthDate is present and parseable, add as date literal\n",
    "    birth_str = row.get(\"birthDate\", \"\")\n",
    "    if pd.notna(birth_str) and birth_str.strip():\n",
    "        try:\n",
    "            # Validate the date string\n",
    "            parsed_date = datetime.strptime(birth_str, \"%Y-%m-%d\")\n",
    "            # If valid, add it as an XSD.date literal\n",
    "            graph.add((author_uri, BIRTH_DATE, Literal(parsed_date.date(), datatype=XSD.date)))\n",
    "        except ValueError:\n",
    "            # Skip invalid dates and print a warning\n",
    "            print(f\"Warning: Invalid date format '{birth_str}' for author '{row['authorLabel']}'. Skipping.\")\n",
    "\n",
    "    \n",
    "    # If there's nationality/language, add it\n",
    "    natlang = row.get(\"combinedNationalityOrLanguage\", \"\")\n",
    "    if pd.notna(natlang) and natlang.strip():\n",
    "        # We can further split if you suspect multiple nationalities in one row\n",
    "        # but the sample only seems to have one. We'll treat it as a single string.\n",
    "        # If multiple, you'd parse similarly to how we parse genres/books.\n",
    "        natlang_uri = add_natlang(natlang.title().strip())\n",
    "        graph.add((author_uri, HAS_NATLANG, natlang_uri))\n",
    "\n",
    "    # Add genre links\n",
    "    for g in row['genres_list']:\n",
    "        genre_uri = add_genre(g)\n",
    "        graph.add((author_uri, HAS_GENRE, genre_uri))\n",
    "    \n",
    "    # Add book links\n",
    "    for b in row['books_list']:\n",
    "        book_uri = add_book(b)\n",
    "        graph.add((author_uri, WROTE_BOOK, book_uri))\n",
    "\n",
    "# Iterate over each author row and add them to the graph\n",
    "for idx, row in df.iterrows():\n",
    "    add_author(row)\n",
    "\n",
    "df_adaptations = pd.read_csv(\"adaptations_data.csv\")\n",
    "\n",
    "def add_author_resource(author_name, birthdate=None):\n",
    "    \"\"\"\n",
    "    Create or retrieve an Author resource by name.\n",
    "    Optionally add birthdate if provided.\n",
    "    \"\"\"\n",
    "    if not author_name:\n",
    "        return None\n",
    "    if author_name not in known_authors:\n",
    "        author_uri = safe_uri(BASE, f\"author_{author_name}\")\n",
    "        graph.add((author_uri, RDF.type, AUTHOR_CLASS))\n",
    "        graph.add((author_uri, NAME, Literal(author_name)))\n",
    "        # If birthdate is valid, add it\n",
    "        if birthdate and pd.notna(birthdate):\n",
    "            print(birthdate)\n",
    "            try:\n",
    "                parsed_date = datetime.strptime(birthdate.strip(), \"%Y-%m-%d\")\n",
    "                graph.add((author_uri, BIRTH_DATE, Literal(parsed_date.date(), datatype=XSD.date)))\n",
    "            except ValueError:\n",
    "                pass\n",
    "        known_authors[author_name] = author_uri\n",
    "    return known_authors[author_name]\n",
    "\n",
    "\n",
    "def add_film(film_title):\n",
    "    \"\"\"\n",
    "    Create or retrieve a Film resource by title.\n",
    "    \"\"\"\n",
    "    if not film_title:\n",
    "        return None\n",
    "    if film_title not in known_films:\n",
    "        film_uri = safe_uri(BASE, f\"film_{film_title}\")\n",
    "        graph.add((film_uri, RDF.type, FILM_CLASS))\n",
    "        graph.add((film_uri, RDFS.label, Literal(film_title)))\n",
    "        graph.add((film_uri, NAME, Literal(film_title)))\n",
    "        known_films[film_title] = film_uri\n",
    "    return known_films[film_title]\n",
    "\n",
    "for idx, row in df_adaptations.iterrows():\n",
    "    film_title  = row.get('filmTitle', '')\n",
    "    film_genre  = row.get('filmGenre', '')\n",
    "    book_title  = row.get('bookTitle', '')\n",
    "    book_genre  = row.get('bookGenre', '')\n",
    "    author_id   = row.get('author', '')      # Possibly an ID if any\n",
    "    author_name = row.get('authorName', '')\n",
    "    birthdate   = row.get('birthDate', '')\n",
    "    \n",
    "    # 1. Add or get the Film resource\n",
    "    film_uri = add_film(film_title)\n",
    "    \n",
    "    if film_uri:\n",
    "        # 2. (Optional) Add film genre if present\n",
    "        if film_genre:\n",
    "            # either reuse hasGenre or define a new property\n",
    "            fg_uri = add_genre(film_genre)\n",
    "            graph.add((film_uri, HAS_GENRE, fg_uri))\n",
    "\n",
    "        # 3. If there's a bookTitle, link film -> book via adaptedFromBook\n",
    "        if book_title:\n",
    "            book_uri = add_book(book_title)\n",
    "            graph.add((film_uri, ADAPTED_FROM_BOOK, book_uri))\n",
    "            \n",
    "            # If there's a bookGenre, you can link the book to it\n",
    "            if book_genre:\n",
    "                bg_uri = add_genre(book_genre)\n",
    "                graph.add((book_uri, HAS_GENRE, bg_uri))\n",
    "    \n",
    "        # 4. If an author is mentioned, add or get the Author resource\n",
    "        if author_name:\n",
    "            # Reuse the new helper to create the author\n",
    "            a_uri = add_author_resource(author_name, birthdate)\n",
    "            # Decide whether to link the Film directly to the Author\n",
    "            # If you have a property like 'hasAuthor' or 'directedBy' or 'writtenBy', you can add it here.\n",
    "            # Example (uncomment if you want):\n",
    "            # graph.add((film_uri, ONS.hasAuthor, a_uri))\n",
    "            pass\n",
    "\n",
    "\n",
    "# Finally, serialize to an .owl (RDF/XML) file\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_OWL_FILE = f\"authors_ontology_{timestamp}.owl\"\n",
    "\n",
    "try:\n",
    "    graph.serialize(destination=OUTPUT_OWL_FILE, format='application/rdf+xml')\n",
    "    print(f\"Ontology successfully saved as {OUTPUT_OWL_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to save ontology: {e}\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of triples: 33381\n",
      "Number of distinct classes: 5\n",
      "Number of distinct properties: 8\n",
      "Number of authors: 1676\n",
      "Number of genres: 719\n",
      "Number of books: 4299\n",
      "Number of nationalities or languages: 165\n"
     ]
    }
   ],
   "source": [
    "num_triples = len(graph)\n",
    "distinct_classes = set(graph.subjects(RDF.type, RDFS.Class))\n",
    "distinct_properties = set(graph.predicates())\n",
    "\n",
    "# You can also count specific instances like authors, books, etc.\n",
    "num_authors = len(set(graph.subjects(RDF.type, AUTHOR_CLASS)))\n",
    "num_genres = len(set(graph.subjects(RDF.type, GENRE_CLASS)))\n",
    "num_books = len(set(graph.subjects(RDF.type, BOOK_CLASS)))\n",
    "num_natlangs = len(set(graph.subjects(RDF.type, NATLANG_CLASS)))\n",
    "\n",
    "print(\"Total number of triples:\", num_triples)\n",
    "print(\"Number of distinct classes:\", len(distinct_classes))\n",
    "print(\"Number of distinct properties:\", len(distinct_properties))\n",
    "print(\"Number of authors:\", num_authors)\n",
    "print(\"Number of genres:\", num_genres)\n",
    "print(\"Number of books:\", num_books)\n",
    "print(\"Number of nationalities or languages:\", num_natlangs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
